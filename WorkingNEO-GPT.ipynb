{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/neo-gpt-humanoid/blob/main/WorkingNEO-GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgfhFoA8WI9J"
      },
      "source": [
        "#GPT NEO based discord chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eq1gbpUWR1h"
      },
      "source": [
        "## Discord API\n",
        "You just need to insert your discord API and then run all the cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hSR9YYeVaPJ"
      },
      "source": [
        "discord_token = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2NFHj4tWY9z"
      },
      "source": [
        "##Module installation\n",
        "this will install all the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJmPcofa006"
      },
      "source": [
        "!pip install transformers\n",
        "!pip3 install discord.py\n",
        "!pip install nest_asyncio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3jougHXOfS"
      },
      "source": [
        "##Download and load GPT NEO model.\n",
        "It will take a little bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyudeREf1uZQ"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrBHO29EzInM"
      },
      "source": [
        "##Mode setup\n",
        "You can use this cell to select or create the desired mode\n",
        "To create a mode just follow this example:\n",
        "\n",
        "\n",
        "```python\n",
        "modes['mode_name'] = { 'prompt' : 'insert text that is put at the beginning of the input',\n",
        "                        'ai' : 'insert text before GPT messages',\n",
        "                        'human' : 'insert text befor human messages',\n",
        "                        'end' : 'a separator applied at the end of every message'\n",
        "                      }\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjn1cPP75RAk"
      },
      "source": [
        "modes = dict()\n",
        "\n",
        "modes['chat'] = {'prompt' : 'I want you to act like Elon Musk from Tesla . I want you to respond and answer like Elon Musk using the tone, manner and vocabulary Elon Musk would use. Do not write any explanations. Only answer like Elon Musk. You must know a lot of the knowledge of Elon Musk.\\n\\n',\n",
        "                           'human' : 'You: ',\n",
        "                           'ai' : 'Friend: ',\n",
        "                            'end' : '\\n'}\n",
        "\n",
        "modes['tldr'] = {'prompt' : 'Text Summarization\\n\\n',\n",
        "                  'human' : '',\n",
        "                  'ai' : '\\n\\nTL;DR: ',\n",
        "                  'end' : ''}\n",
        "\n",
        "modes['void'] = {'prompt' : '',\n",
        "                 'human' : '',\n",
        "                 'ai' : '',\n",
        "                 'end' : ''}\n",
        "\n",
        "mode = modes['chat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-F89u9ccD0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjWp2WizM2J"
      },
      "source": [
        "##Function to get GPT's answer from discord chat history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMY3qq5c5tmN"
      },
      "source": [
        "You can play with time_limit and max_length using the sliders. Time limit is very useful if you want fast replies by GPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hspd_O3maydb"
      },
      "source": [
        "time_limit = 100 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "max_length = 1543 #@param {type:\"slider\", min:100, max:5000, step:1}\n",
        "\n",
        "def AI_answer(string):\n",
        "  in_string = mode['prompt'] + string\n",
        "  inputs = tokenizer.encode(in_string, return_tensors='pt')\n",
        "  inputs = inputs.cuda()\n",
        "  outputs = model.generate(inputs, max_length=max_length, do_sample=True, max_time=time_limit)\n",
        "  text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  stripped_text = text[len(in_string):]\n",
        "\n",
        "  #preprocessing answer\n",
        "  if mode['human'] is not '' and mode['ai'] is not '':\n",
        "    stripped_text = stripped_text.split(mode['ai'])[1]\n",
        "    stripped_text = stripped_text.split(mode['human'])[0]\n",
        "  return stripped_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nnXEh6zUXd"
      },
      "source": [
        "##Discord bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKWSksHfd7NO"
      },
      "source": [
        "import discord\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "client = discord.Client(intents=discord.Intents.default())\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    print('We have logged in as {0.user}'.format(client))\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    messages = []\n",
        "    async for m in message.channel.history():\n",
        "        messages.append(m)\n",
        "\n",
        "    #create input string\n",
        "    in_string = ''\n",
        "    for message in reversed(messages):\n",
        "      \n",
        "      if message.author == client.user:\n",
        "        in_string += mode['ai']\n",
        "      else:\n",
        "        in_string += mode['human']\n",
        "      in_string += message.content + mode['end']\n",
        "\n",
        "    output = AI_answer(in_string)\n",
        "\n",
        "    await message.channel.send(output)\n",
        "\n",
        "client.run(discord_token)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}